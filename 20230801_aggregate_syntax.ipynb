{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:34:00.158394Z",
     "start_time": "2023-08-01T11:33:59.873771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'classes': [{'class': 'Knowledge_chunk',\n   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n    'cleanupIntervalSeconds': 60,\n    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n   'moduleConfig': {'generative-openai': {},\n    'text2vec-openai': {'model': 'ada',\n     'modelVersion': '002',\n     'type': 'text',\n     'vectorizeClassName': True}},\n   'multiTenancyConfig': {'enabled': False},\n   'properties': [{'dataType': ['text'],\n     'description': \"This property was generated by Weaviate's auto-schema feature on Fri Jul 21 14:52:11 2023\",\n     'indexFilterable': True,\n     'indexSearchable': True,\n     'moduleConfig': {'text2vec-openai': {'skip': False,\n       'vectorizePropertyName': False}},\n     'name': 'source_title',\n     'tokenization': 'word'},\n    {'dataType': ['text'],\n     'description': \"This property was generated by Weaviate's auto-schema feature on Fri Jul 21 14:52:11 2023\",\n     'indexFilterable': True,\n     'indexSearchable': True,\n     'moduleConfig': {'text2vec-openai': {'skip': False,\n       'vectorizePropertyName': False}},\n     'name': 'body',\n     'tokenization': 'word'},\n    {'dataType': ['number'],\n     'description': \"This property was generated by Weaviate's auto-schema feature on Fri Jul 21 14:52:11 2023\",\n     'indexFilterable': True,\n     'indexSearchable': False,\n     'moduleConfig': {'text2vec-openai': {'skip': False,\n       'vectorizePropertyName': False}},\n     'name': 'chunk_number'},\n    {'dataType': ['text'],\n     'description': \"This property was generated by Weaviate's auto-schema feature on Fri Jul 21 14:52:11 2023\",\n     'indexFilterable': True,\n     'indexSearchable': True,\n     'moduleConfig': {'text2vec-openai': {'skip': False,\n       'vectorizePropertyName': False}},\n     'name': 'source_path',\n     'tokenization': 'word'}],\n   'replicationConfig': {'factor': 1},\n   'shardingConfig': {'virtualPerPhysical': 128,\n    'desiredCount': 1,\n    'actualCount': 1,\n    'desiredVirtualCount': 128,\n    'actualVirtualCount': 128,\n    'key': '_id',\n    'strategy': 'hash',\n    'function': 'murmur3'},\n   'vectorIndexConfig': {'skip': False,\n    'cleanupIntervalSeconds': 300,\n    'maxConnections': 64,\n    'efConstruction': 128,\n    'ef': -1,\n    'dynamicEfMin': 100,\n    'dynamicEfMax': 500,\n    'dynamicEfFactor': 8,\n    'vectorCacheMaxObjects': 1000000000000,\n    'flatSearchCutoff': 40000,\n    'distance': 'cosine',\n    'pq': {'enabled': False,\n     'bitCompression': False,\n     'segments': 0,\n     'centroids': 256,\n     'trainingLimit': 100000,\n     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n   'vectorIndexType': 'hnsw',\n   'vectorizer': 'text2vec-openai'}]}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate\n",
    "client = weaviate.Client(\"http://localhost:8082\")\n",
    "client.schema.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "response = (\n",
    "    client.query.get(\"Knowledge_chunk\", [\"body\"])\n",
    "    .with_limit(2)\n",
    "    .with_bm25(query=\"search\")\n",
    "    .do()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:37:05.031410Z",
     "start_time": "2023-08-01T11:37:05.012621Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "{'data': {'Get': {'Knowledge_chunk': [{'body': \"https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-chunk-documents\\n\\nChunking large documents for vector search solutions in Cognitive Search\\nArticle\\n07/11/2023\\n4 contributors\\nIn this article\\nWhy is chunking important?\\nHow chunking fits into the workflow\\nSimple example of how to create chunks with sentences\\nTry it out: Chunking and vector embedding generation sample\\nSee also\\n Important\\n\\nVector search is in public preview under supplemental terms of use. It's available through the Azure portal, preview REST API, and alpha SDKs.\\n\\nThis article describes several approaches for chunking large documents so that you can generate embeddings for vector search. Chunking is only required if source documents are too large for the maximum input size imposed by models.\\n\\nWhy is chunking important?\\nThe models\"},\n    {'body': 'example, when dealing with large documents, you might use variable-sized chunks, but also append the document title to chunks from the middle of the document to prevent context loss.\\n\\nContent overlap considerations\\nWhen you chunk data, overlapping a small amount of text between chunks can help preserve context. We recommend starting with an overlap of approximately 10%. For example, given a fixed chunk size of 256 tokens, you would begin testing with an overlap of 25 tokens. The actual amount of overlap varies depending on the type of data and the specific use case, but we have found that 10-15% works for many scenarios.\\n\\nFactors for chunking data\\nWhen it comes to chunking data, think about these factors:\\n\\nShape and density of your documents. If you need intact text or'}]}}}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:37:05.249845Z",
     "start_time": "2023-08-01T11:37:05.247250Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Possible search syntax:\n",
    "\n",
    "Search\n",
    "\n",
    "What about a syntax like this, separating:\n",
    "- Properties always available for Get\n",
    "- Optional search operator (vector searches, bm25, hybrid)\n",
    "- Optional boolean filter\n",
    "- Chained 2nd operation (Generate / Ask)\n",
    "\n",
    "```python\n",
    "from weaviate.weaviate_classes import NearText, Filter, FilterOperator, Metadata\n",
    "\n",
    "search_response = collection.search.get(\n",
    "    # ===== Parameters always available for `GraphQL/get`\n",
    "    properties=[\"chunk\", \"title\"],\n",
    "    limit=2,\n",
    "    metadata=Metadata(vector=True),\n",
    "\n",
    "    # ===== And optional parameters\n",
    "    # e.g. `NearText`, `NearVector`, `BM25Search`, `HybridSearch`, etc.\n",
    "    search_operator=NearText(\n",
    "        query=\"multi tenancy\",\n",
    "        distance=0.85,\n",
    "        # Also autocut, certainty, etc.\n",
    "    ),\n",
    "\n",
    "    # Add Boolean filters\n",
    "    filter=Filter(\n",
    "        operator=FilterOperator.LessThan,  # Enum\n",
    "        path=[\"chunk_no\"],\n",
    "        value=5\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "For Generative / Ask, chaining makes sense to me. Because generate is a two-step query conceptually. What do you think?\n",
    "```python\n",
    "from weaviate.weaviate_classes import NearText\n",
    "\n",
    "generative_response = collection.search.get(\n",
    "    limit=2,\n",
    "    properties=[\"chunk\", \"title\"],\n",
    "    search_operator=NearText(\n",
    "        query=\"multi tenancy\",\n",
    "    ),\n",
    ").with_generate(\n",
    "    single_prompt=\"turn this into a country song verse\",\n",
    "    properties=[\"chunk\"]\n",
    ")\n",
    "```\n",
    "\n",
    "Two-step generative\n",
    "In some situations this might be nice. Maybe we could do this with returned IDs? ðŸ¤”\n",
    "```python\n",
    "generative_response = search_response.with_generate(\n",
    "    single_prompt=\"turn this into a country song verse\",\n",
    "    properties=[\"chunk\"]\n",
    ")\n",
    "```\n",
    "\n",
    "Aggregate\n",
    "\n",
    "The `Get` query above should translate relatively well to aggregate, because `search_operator` and `filter` are universal. Then the user needs to select the meta properties.\n",
    "```python\n",
    "from weaviate.weaviate_classes import NearText, Filter, FilterOperator\n",
    "\n",
    "search_response = collection.search.aggregate(\n",
    "    # ===== Parameters always available for `GraphQL/get`\n",
    "    meta_properties=[  # *shrug* maybe something like this?\n",
    "        {\"title\": [\n",
    "            MetaProperty.Text.COUNT,\n",
    "            MetaProperty.Text.Top_occurrences.VALUE,\n",
    "            MetaProperty.Text.Top_occurrences.COUNT,\n",
    "        ]},\n",
    "        {\"chunk_no\": [\n",
    "            MetaProperty.Int.COUNT,\n",
    "            MetaProperty.Int.MEAN,\n",
    "        ]},\n",
    "    ],\n",
    "    object_limit=1000,\n",
    "\n",
    "    # ===== And optional parameters\n",
    "    search_operator=NearText(\n",
    "        query=\"multi tenancy\",\n",
    "        distance=0.85,\n",
    "    ),\n",
    "    filter=Filter(\n",
    "        operator=FilterOperator.LessThan,\n",
    "        path=[\"chunk_no\"],\n",
    "        value=5\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "data.search.aggregate(\n",
    "    searchOperators = [\n",
    "        NearText(query=\"italian pizza\"),\n",
    "        Filter(property=\"price\", operator=\"GreaterThan\", value=100)\n",
    "    ],\n",
    "    meta_properties=[\n",
    "        {\"title\": [\n",
    "            MetaProperty.Text.COUNT,\n",
    "            MetaProperty.Text.Top_occurrences.VALUE,\n",
    "            MetaProperty.Text.Top_occurrences.COUNT,\n",
    "        ]},\n",
    "        {\"page_no\": [\n",
    "            MetaProperty.Int.COUNT,\n",
    "            MetaProperty.Int.MEAN,\n",
    "        ]},\n",
    "    ],\n",
    "    count=True,\n",
    "    limit=10,\n",
    ")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
